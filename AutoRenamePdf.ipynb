{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "import os\n",
    "# os.environ['TIKA_SERVER_JAR'] = \"/var/folders/l6/2rm09dyd0d58tk10yvjy26f80000gn/T/tika-server.jar\"\n",
    "# os.environ['TIKA_SERVER_JAR'] = \"/Users/chenchen/Desktop/tika-server-1.19.jar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp /Users/chenchen/Desktop/tika-server-1.19.jar /var/folders/l6/2rm09dyd0d58tk10yvjy26f80000gn/T/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the doi\n",
    "def get_doi(parsed_content):\n",
    "    import re\n",
    "    doi_pattern = re.compile('doi:?\\s*([a-z0-9.\\/]+)', re.I)\n",
    "    if doi_pattern.search(parsed_content):\n",
    "        doi = doi_pattern.search(parsed_content).group(1)\n",
    "        return doi\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the json from cross\n",
    "def cross_doi(doi):\n",
    "    import requests\n",
    "    url_doi = \"https://api.crossref.org/works/\"\n",
    "    search_url = url_doi + doi\n",
    "    response = requests.get(search_url)\n",
    "    print(response.json()['message']['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File zelken2016.pdf have the doi: 10.1097/SAP.0000000000000759\n",
      "Silicone-Polytetrafluoroethylene Composite Implants for Asian Rhinoplasty\n",
      "File li2016.pdf have the doi: 10.1097/SAP.0000000000000841\n",
      "An Overview of Asian Rhinoplasty\n",
      "File stucker1999.pdf have no doi\n"
     ]
    }
   ],
   "source": [
    "# loop through this folder\n",
    "import os\n",
    "from tika import parser\n",
    "for file in os.listdir('.'):\n",
    "    if file.lower().endswith('.pdf'):\n",
    "        parsed = parser.from_file(file)\n",
    "        doi = get_doi(parsed['content'])\n",
    "        if not doi:\n",
    "            print(\"File {} have no doi\".format(file))\n",
    "#             print(parsed['content'])\n",
    "        else:\n",
    "            print(\"File {} have the doi: {}\".format(file, doi))\n",
    "            cross_doi(doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# possible no doi\n",
    "1. The paper is old\n",
    "2. The paper is too new \n",
    "3. The paper is not published yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first lines of \n",
    "from tika import parser\n",
    "from Bio import Entrez, Medline\n",
    "# define the email to prevent block\n",
    "Entrez.email = 'chenfmmu@163.com'\n",
    "\n",
    "# get the first n lines excluding the trailing line breaks\n",
    "def getfirstlines(pdffile, n=3):\n",
    "    from tika import parser\n",
    "    splitter = \"\\n\\n\"\n",
    "    parsed = parser.from_file(file)\n",
    "    content = parsed['content'].strip().split(splitter)\n",
    "\n",
    "    return content[:n]\n",
    "\n",
    "searchlist = getfirstlines('stucker1999.pdf')\n",
    "\n",
    "# make the term and search in the title\n",
    "TERM = searchlist[0] + \"[title]\"\n",
    "# the count of pubmed ids we want to get\n",
    "MAX_COUNT = 10\n",
    "# get the idlist of the search\n",
    "handle = Entrez.esearch(db='pubmed', retmax=MAX_COUNT, term=TERM)\n",
    "result = Entrez.read(handle)\n",
    "idlist = result['IdList']\n",
    "# get the information of idlist\n",
    "h = Entrez.efetch(db='pubmed', id=idlist, rettype='medline', retmode='text')\n",
    "records = Medline.parse(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance of placing Gore-Tex in the subperiosteal plane for augmentation rhinoplasty.\n",
      "22801183\n",
      "Gore-Tex nasal augmentation: a 26-year perspective.\n",
      "21422447\n",
      "Are polytetrafluoroethylene (Gore-Tex) implants an alternative material for nasal dorsal augmentation in Asians?\n",
      "21119414\n",
      "Histological study of expanded polytetrafluoroethylene (Gore-Tex) implanted in the human nose.\n",
      "19146003\n",
      "The use of expanded polytetrafluoroethylene (Gore-Tex) in rhinoplasty.\n",
      "17549553\n",
      "Augmentation of the nasal dorsum using Gore-Tex: intermediate results of a retrospective analysis of experience in 66 patients.\n",
      "11437844\n",
      "Nasal augmentation using Gore-Tex. A 10-year experience.\n",
      "10937089\n",
      "Gore-tex augmentation grafting in rhinoplasty--is it safe?\n",
      "9857319\n",
      "Gore-Tex nasal augmentation.\n",
      "8532794\n",
      "Gore-Tex for nasal augmentation: a recent series and a review of the literature.\n",
      "8534022\n",
      "Nasal Augmentation Using Gore-Tex[title]\n"
     ]
    }
   ],
   "source": [
    "# filter the pubmed list of information to find the match\n",
    "# The criteria is yet to be refined \n",
    "for r in records:\n",
    "    print(r['TI'])\n",
    "    print(r['PMID'])\n",
    "print(TERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. I assume that the first several lines (default to 2 lines) is the title lines especially for the first line. The criteria for the title lines should be refined. For example, use the other boundary lines. \n",
    "2. Technique to be used: Collect several papers without doi in the text. Manually extract the title lines and store it in a variable. Use Machine Learning to set the boundary for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
